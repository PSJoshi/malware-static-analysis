#!/usr/bin/env python

import argparse
import magic
import hashlib
import ssdeep
import os
import sys
import datetime
import logging
import math
import pefile
import peutils
import struct
import re
import base64
import string
from collections import Counter
from yara_checks import yara_checks

"""
Some useful links:
http://breakinsecurity.com/pe-format-manipulation-with-pefile/
https://github.com/ClickSecurity/data_hacking/blob/master/pefile_classification/pe_features.py#L317
https://github.com/hiddenillusion/AnalyzePE/blob/master/AnalyzePE.py
https://github.com/Ice3man543/MalScan/blob/master/malscan.py
https://github.com/secrary/SSMA
https://github.com/Rurik/FileInfo/blob/master/FileInfo.py

PE file format:
https://github.com/deptofdefense/SalSA/wiki/PE-File-Format
https://msdn.microsoft.com/en-us/library/windows/desktop/ms680547(v=vs.85).aspx
"""
# setup logging
logging.basicConfig(stream=sys.stdout,level = logging.DEBUG)
logger = logging.getLogger(__name__)

IMAGE_FILE_MACHINE_I386=332
IMAGE_FILE_MACHINE_IA64=512
IMAGE_FILE_MACHINE_AMD64=34404

def is_exe(filename):
    flg = False
    try:
        pe = pefile.PE(filename)
        flg = True
    except Exception,e:
        logger.error("Error while loading {} file".format(filename,e.message),exc_info=True)
    return flg 

def convertToUTF8(s):
    if (isinstance(s, unicode)):
        return s.encode( "utf-8" )
    try:
        u = unicode( s, "utf-8" )
    except:
        return str(s)
    utf8 = u.encode( "utf-8" )

    return utf8

def RemoveNulls(s):
    s = s.split('\x00', 1)[0]
    return s.decode('ascii', 'ignore')

def is_hex_old(s):
    return re.match(r'\b[0-9a-fA-F]+\b',s)
    #return re.match(r'^[0-9a-fA-F]+$', s) is not None

def is_hex(s):
    return all(c in string.hexdigits for c in s)

def isBase64(s):
    try:
        if base64.b64encode(base64.b64decode(s)) == s:
            return True;
    except Exception:
        pass;
    return False;

def pe_sections(filename):
    sections = list()
    try:
        pe = pefile.PE(filename)
        for section in pe.sections:
            if section:
                logger.info("Section name - {}".format(section.Name.decode('utf-8')))
                logger.info("Virtual address - {}".format(hex(section.VirtualAddress)))
                logger.info("Virtual size - {}".format(hex(section.Misc_VirtualSize)))
                logger.info("Size of raw data - {}".format(section.SizeOfRawData))
                logger.info("Section entropy - {}".format(section.get_entropy()))
                sections.append([
                               {'Section name':section.Name.decode('utf-8')},
                               {'Virtual address':hex(section.VirtualAddress)},
                               {'Virtual size':hex(section.Misc_VirtualSize)},
                               {'Raw data size':section.SizeOfRawData},
                               {'Section entropy':section.get_entropy()}
                              ])
                
    except Exception,e:
        logger.error("Error while getting PE section(s) of file {} - {}".format(filename,e.message),exc_info=True)

    return sections
  
def dos_headers(filename):
    dos_header_fields = list()
    try:
        pe = pefile.PE(filename)
        for field in pe.DOS_HEADER.dump():
             dos_header_fields.append(field)
    except Exception,e:
        logger.error("Error while getting DOS Headers information of file {} - {}".format(filename,e.message),exc_info=True)

    return dos_header_fields

def get_import_dlls(filename):
    imported_dlls = list()

    try:
        pe = pefile.PE(filename)
        for entry in pe.DIRECTORY_ENTRY_IMPORT:
            imported_dlls.append(entry.dll.decode('utf-8'))

    except Exception,e:
        logger.error("Error while getting imported DLL information of file {} - {}".format(filename,e.message),exc_info=True) 

    return imported_dlls

def get_import_dll_functions(filename):

    import_dll_functions = list()

    try:
        pe = pefile.PE(filename)
        for entry in pe.DIRECTORY_ENTRY_IMPORT:
            dll_functions = [{'name': func.name.decode('utf-8'),'address':func.address} for func in entry.imports]
            import_dll_functions.append({entry.dll.decode('utf-8'):dll_functions}) 
    
    except Exception,e:
        logger.error("Error while getting import DLL function names for file {} - {}".format(filename,e.message),exc_info=True)

    return import_dll_functions

def check_kernel_mode(filename):
   # check if file supports kernel mode of operation
   has_kernel_mode = False

   try:
       pe = pefile.PE(filename)
       for entry in pe.DIRECTORY_ENTRY_IMPORT:
           if (entry.dll == 'ntoskrnl.exe'):
               has_kernel_mode = True
        
   except Exception,e:
       logger.error("Error in checking if the file {} requires/supports kernel mode of operation - {}"
       .format(filename,e.message),exc_info=True)

   return has_kernel_mode

def check_dynamic_loaders(filename):
    # check if dynamic loaders are supported
    dynamic_loader = False
    try:
        pe = pefile.PE(filename)
        i = 0
        for entry in pe.DIRECTORY_ENTRY_IMPORT:
            if (entry.dll == 'KERNEL32.DLL'):
                for imp in entry.imports:  
                    i += 1
        if (i == 0) or (i <= 10):
            dynamic_loader = True
        
    except Exception,e:
        logger.error("Error while checking dynamic loaders in file {} - {}"
        .format(filename,e.message),exc_info=True)

    return dynamic_loader

def get_antidebug_functions(filename):

    anti_debug_functions = ['CheckRemoteDebuggerPresent', 'FindWindow',
                           'GetWindowThreadProcessId', 'IsDebuggerPresent',
                           'OutputDebugString', 'Process32First', 'Process32Next',
                           'TerminateProcess', 'UnhandledExceptionFilter',
                           'ZwQueryInformation','NtQueryInformationProcess',
                           'NtSetInformationThread']
    response = list()
    try:
        pe = pefile.PE(filename)
        if hasattr(pe, "DIRECTORY_ENTRY_IMPORT"):
            for entry in pe.DIRECTORY_ENTRY_IMPORT:
                for imp in entry.imports:
                    if imp:
                        for fun in anti_debug_functions:
                            if imp.name.find(fun)>=0:
                                response.append("%s %s" %(hex(imp.address),imp.name))
        else:
            logger.info("No 'DIRECTORY_ENTRY_IMPORT' section file {}".format(filename))
        if response:
            return '\n'.join(response)
        else:
            return None 
    except Exception,e:
        logger.error("Error while checking presence of anti-debugging functions"
                     " in the file {} - {}".format(filename,e.message),exc_info=True)

def antiVM_checks(filename):
    vm_tricks = list()
    try:
        """
        source: https://code.google.com/p/pyew
        """
        vm_signatures = {
        "Red Pill":"\x0f\x01\x0d\x00\x00\x00\x00\xc3",
        "VirtualPc trick":"\x0f\x3f\x07\x0b",
        "VMware trick":"VMXh",
        "VMCheck.dll":"\x45\xC7\x00\x01",
        "VMCheck.dll for VirtualPC":"\x0f\x3f\x07\x0b\xc7\x45\xfc\xff\xff\xff\xff",
        "Xen":"XenVMM",
        "Bochs & QEmu CPUID Trick":"\x44\x4d\x41\x63",
        "Torpig VMM Trick": "\xE8\xED\xFF\xFF\xFF\x25\x00\x00\x00\xFF\x33\xC9\x3D\x00\x00\x00\x80\x0F\x95\xC1\x8B\xC1\xC3",
        "Torpig (UPX) VMM Trick": "\x51\x51\x0F\x01\x27\x00\xC1\xFB\xB5\xD5\x35\x02\xE2\xC3\xD1\x66\x25\x32\xBD\x83\x7F\xB7\x4E\x3D\x06\x80\x0F\x95\xC1\x8B\xC1\xC3"
        }

        vm_strings  = {
		"Virtual Box":"VBox",
		"VMware":"WMvare"
        }
         
        with open(filename,'rb') as f:
            buf = f.read()
            # check if virtualbox or vmplayer is present 
            for item in vm_strings:
                match = re.findall(vm_strings[item], buf, re.IGNORECASE | re.MULTILINE)
                if match:
                    vm_tricks.append(item)

            for sig in vm_signatures:
                if buf.find(vm_signatures[sig][::-1]) > -1:
                    vm_tricks.append(sig)
        if vm_tricks:  
            return '\n'.join(vm_tricks) 
        else: return None

    except Exception,e:
        logger.error("Error while checking presence of anti-Virtual Machine functions"
                     " in the file {} - {}".format(filename,e.message),exc_info=True)

def find_ip_address(filename):
    ip_list = list()
    ip_regex = r'(?:[\d]{1,3})\.(?:[\d]{1,3})\.(?:[\d]{1,3})\.(?:[\d]{1,3})$'
    try:
        with open(filename, 'rb') as f:
            buf = f.read()
            regex = re.findall(ip_regex,buf)
            if regex is not None:
                for match in regex:
                    if match not in ip_list:
                        ip_list.append(match)

    except Exception,e:
        logger.error("Error while finding IP addresses in file - {}".format(filename,e.message),exc_info=True)
   
    if ip_list:
        return ','.join(ip_list)
    else: return None

def find_urls(filename):
    url_list = list()
    url_regex = r'https?://(?:[-\w.]|(?:%[\da-fA-F]{2}))+'
    try:
        with open(filename, 'rb') as f:
            buf = f.read()
            regex = re.findall(url_regex,buf)
            if regex is not None:
                for match in regex:
                    if match not in url_list:
                        url_list.append(match)

    except Exception,e:
        logger.error("Error while finding urls in the file - {}".format(filename,e.message),exc_info=True)
   
    if url_list:
        return ','.join(url_list)
    else: return None

def find_emails(filename):
    email_list = list()
    #email_regex = r'^.+@([?)[a-zA-Z0-9-.]+.([a-zA-Z]{2,3}|[0-9]{1,3})(]?)$'
    #email_regex = r'\S+@\S+'
    email_regex = r'^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}$.'
    try:
        with open(filename, 'rb') as f:
            buf = f.read()
            regex = re.findall(email_regex,buf)
            if regex is not None:
                for match in regex:
                    if match not in email_list:
                        email_list.append(match)

    except Exception,e:
        logger.error("Error while finding urls in the file - {}".format(filename,e.message),exc_info=True)
   
    if email_list:
        return ','.join(email_list)
    else: return None

 
 
def suspicious_api_calls(filename):

    suspicious_apis = ['accept','AddCredentials','bind','CertDeleteCertificateFromStore',
'CheckRemoteDebuggerPresent','CloseHandle','closesocket','connect','ConnectNamedPipe',
'CopyFile','CreateFile','CreateProcess','CreateToolhelp32Snapshot','CreateFileMapping',
'CreateRemoteThread','CreateDirectory','CreateService','CreateThread','CryptEncrypt',
'DeleteFile','DeviceIoControl','DisconnectNamedPipe','DNSQuery','EnumProcesses',
'ExitProcess','ExitThread','FindWindow','FindResource','FindFirstFile','FindNextFile',
'FltRegisterFilter','FtpGetFile','FtpOpenFile','GetCommandLine','GetComputerName',
'GetCurrentProcess','GetThreadContext','GetDriveType','GetFileSize','GetFileAttributes',
'GetHostByAddr','GetHostByName','GetHostName','GetModuleHandle','GetModuleFileName',
'GetProcAddress','GetStartupInfo','GetSystemDirectory','GetTempFileName','GetTempPath',
'GetTickCount','GetUpdateRect','GetUpdateRgn','GetUserNameA','GetUrlCacheEntryInfo',
'GetVersionEx','GetWindowsDirectory','GetWindowThreadProcessId','HttpSendRequest',
'HttpQueryInfo','IcmpSendEcho','IsBadReadPtr','IsBadWritePtr','IsDebuggerPresent',
'InternetCloseHandle','InternetConnect','InternetCrackUrl','InternetQueryDataAvailable',
'InternetGetConnectedState','InternetOpen','InternetQueryDataAvailable','InternetQueryOption',
'InternetReadFile','InternetWriteFile','LdrLoadDll','LoadLibrary','LoadLibraryA','LockResource',
'listen','MapViewOfFile','OutputDebugString','OpenFileMapping','OpenProcess','Process32First',
'Process32Next','recv','ReadFile','RegCloseKey','RegCreateKey','RegDeleteKey','RegDeleteValue',
'RegEnumKey','RegOpenKey','ReadProcessMemory','send','sendto','SetFilePointer','SetKeyboardState',
'SetWindowsHook','ShellExecute','Sleep','socket','StartService','TerminateProcess','UnhandledExceptionFilter',
'URLDownload','VirtualAlloc','VirtualFree','VirtualProtect','VirtualAllocEx','WinExec','WriteProcessMemory',
'WriteFile','WSASend','WSASocket','WSAStartup','ZwQueryInformation'
]
    api_calls = list()
    try:    
        
        pe = pefile.PE(filename)
        if hasattr(pe, "DIRECTORY_ENTRY_IMPORT"):
            for entry in pe.DIRECTORY_ENTRY_IMPORT:
                for imp in entry.imports:
                    for api_call in suspicious_apis:
                        if imp.name.find(api_call)>=0:
                            api_calls.append(imp.name) 
    except Exception,e:
        logger.error("Error while checking suspicious call usage for file {} - {}".format(filename,e.message),exc_info=True)
    if api_calls:
        return '\n'.join(api_calls) 
    else: return None

def get_export_symbols(filename):

    export_symbols = list()

    try:
        pe = pefile.PE(filename)
        if hasattr(pe, "DIRECTORY_ENTRY_EXPORT"): 
            for entry in pe.DIRECTORY_ENTRY_EXPORT.symbols:
                export_symbols.append({entry.name.decode('utf-8'):entry.address})

    except Exception,e:
        logger.error("Error while getting exported symbols for file {} - {}".format(filename,e.message),exc_info=True)     

    return export_symbols

def get_extension(filename):
    try:
        'returns ext of the file type using pefile'
        if pe.is_dll() == True:
            return 'dll'
        if pe.is_driver() == True:
            return 'sys'
        if pe.is_exe() == True:
            return 'exe'
        else:
            return 'bin'
    except Exception,e:
        logger.error("Error while getting extension for file {} - {}"
        .format(filename,e.message),exc_info=True)
        return None   

def detect_overlay(filename):
    # good reference - http://struppigel.blogspot.in/2014/05/accurate-overlay-detection.html
    Isoverlay = False
    try:
        offset = 0
        pe = pefile.PE(filename)

        #if not pe.get_overlay():
        #    logger.info("It is good to know that no file overlay detected.")

        for sec in pe.sections:
            pointer_to_raw = sec.PointerToRawData
            size_of_raw = sec.SizeOfRawData
            if offset < size_of_raw + pointer_to_raw:
                offset = size_of_raw + pointer_to_raw
        f_size = os.path.getsize(filename)
        if offset < f_size:
            Isoverlay = True

    except Exception,e:
        logger.error("Error while checking overlay for file {} - {}"
        .format(filename,e.message),exc_info=True)
    return Isoverlay

def compute_entropy(data):
    if not data:
        return 0
    entropy = 0
    for x in range(256):
        prob = float(data.count(chr(x)))/len(data)
        if prob > 0 :
            entropy += -prob*math.log(prob,2)

    return entropy
      
def compute_data_entropy(filename):
    try:
        ent = 0
        counts = Counter()
        with open(filename,'r') as f:
            data=f.read()

        for d in data:
            counts[d] +=1

        probs = [float(c) / len(data) for c in counts.values()]
        probs = [p for p in probs if p > 0.]
    
        for p in probs:
            ent -= p * math.log(p, 2)
    
    except Exception,e:
        logger.error("Error while computing entropy for file {} - {} ".format(filename, e.message), exc_info=True)

    return ent

def compute_md5(filename):
    try:

        return hashlib.md5(filename).hexdigest()

    except Exception,e:
        logger.error("Error while computing md5 hash of file {} - {} ".format(filename, e.message), exc_info=True)

def compute_sha1(filename):
    try:

        return hashlib.sha1(filename).hexdigest()

    except Exception,e:
        logger.error("Error while computing md5 hash of file {} - {} ".format(filename, e.message), exc_info=True)

def ssdeep_hash(filename):
    try:

        return ssdeep.hash_from_file(filename)

    except Exception, e:
        logger.error("Error while computing ssdeep hash of file {} - {}".format(filename, e.message), exc_info=True)

def mime_type(filename):
    try:

        return magic.from_file(filename, mime=True)

    except Exception, e:
        logger.error("Error while determining file type for file {} - {}".format(filename, e.message), exc_info=True) 

def get_file_size(filename):
    try:

        return os.path.getsize(filename)

    except Exception, e:
        logger.error("Error while getting file size for file {} - {}".format(filename, e.message), exc_info=True)

def is_exe(filename):
    with open(filename,'rb') as f:
        # read first two bytes 
        resp_bytes = f.read(2)  
    # not an EXE file
    if resp_bytes !="MZ":
        return False

    else: return True

def is_packed(filename):
    pack_status = False
    try:
        pe_instance = pefile.PE(filename)
        packed = peutils.is_probably_packed(pe_instance)
        if packed == 1:
            pack_status = True       
    except Exception,e:
        logger.error("Error while checking if the file {} is packed using well known"
        " packer programs like UPX etc. - {}".format(filename, e.message), exc_info=True)
    
    return pack_status

def check_sizeofrawdata(filename):
    size_rawdata_check = False
    try:
        pe_instance = pefile.PE(filename)
        no_sections = pe_instance.FILE_HEADER.NumberOfSections
        for i in range(no_sections-1):
            if i == no_sections-1:
                break
            else:
                nextp = pe_instance.sections[i].SizeOfRawData + pe_instance.sections[i].PointerToRawData
                currp = pe_instance.sections[i+1].PointerToRawData
                if nextp != currp:
                    logger.info("The Size Of Raw data value is not valid and it may crash your disassembler/debugger")
                    break
                else:
                    pass

        size_rawdata_check = True

    except Exception, e:
        logger.error("Error while checking size of raw data value(s) in"
        " sections of PE file {} - {}".format(filename, e.message), exc_info=True) 

    return size_rawdata_check 

def check_empty_section_name(filename):
    empty_section_name = False
    try:
        pe_instance = pefile.PE(filename)
        for sec in pe_instance.sections:
            if not re.match("^[.A-Za-z][a-zA-Z]+",sec.Name):
                logger.info("Empty or Non-ASCII section name - {}".format(sec.Name))
                empty_section_name = True
    except Exception,e:
        logger.info("Error while checking empty section name in file"
        " {} - {}".format(filename, e.message), exc_info=True) 

    return empty_section_name 

def check_optional_header_size(filename):
    chk_option_header = True
    try:
        pe_instance = pefile.PE(filename) 
        if pe_instance.FILE_HEADER.SizeOfOptionalHeader != 224:
            logger.debug("Size of optional header is not valid.")
            chk_option_header = False
    except Exception,e:
        logger.info("Error while checking size of optional header for file"
        " - {}".format(filename, e.message), exc_info=True)

    return chk_option_header

def check_optional_header_checksum(filename):
    chk_checksum_header = True
    try:
        pe_instance = pefile.PE(filename) 
        if pe_instance.OPTIONAL_HEADER.CheckSum == 0:
            logger.debug("Optional Header check sum {} is not valid."
            .format(pe_instance.OPTIONAL_HEADER.CheckSum))
            chk_checksum_header = False
    except Exception,e:
        logger.info("Error while checking checksum of optional header for file"
        " - {}".format(filename, e.message), exc_info=True)

    return chk_checksum_header

def check_service_dll(filename):
    is_service_dll = False
    try:
        pe_instance = pefile.PE(filename) 
        if hasattr(pe_instance,"DIRECTORY_ENTRY_EXPORT"):
            for dll_entry in pe_instance.DIRECTORY_ENTRY_EXPORT.symbols:
                if re.match('ServiceMain', dll_entry.name):
                    is_service_dll = True

    except Exception,e:
        logger.info("Error while checking presence of Service DLLs in file {} - {}"
        .format(filename, e.message), exc_info=True)

    return is_service_dll

def get_imports(filename):
    # get number of imports and import symbols
    num_import_symbols = 0
    num_imports = 0
    try:
        pe_instance = pefile.PE(filename) 
        if hasattr(pe_instance,"DIRECTORY_ENTRY_IMPORT"):
            num_imports = len(pe_instance.DIRECTORY_ENTRY_IMPORT)
            for entry in pe_instance.DIRECTORY_ENTRY_IMPORT:
                num_import_symbols += len(entry.imports)
    except Exception,e:
        logger.info("Error while getting number of import symbols in file {} - {}"
         .format(filename,e.message), exc_info=True) 

    return num_imports, num_import_symbols

def get_bound_imports(filename):
    # get number of bounded imports
    num_bound_imports = 0
    num_bound_symbols = 0
    try:
        pe_instance = pefile.PE(filename) 
        if hasattr(pe_instance,"DIRECTORY_ENTRY_BOUND_IMPORT"):
            num_bound_imports = len(pe_instance.DIRECTORY_ENTRY_BOUND_IMPORT)
            bound_symbols = list()
            for entry in pe_instance.DIRECTORY_ENTRY_BOUND_IMPORT:
                num_bound_symbols += len(entry.entries)
    except Exception,e:
        logger.info("Error while getting number of bound imports in file {} - {}"
        .format(filename,e.message), exc_info=True) 

    return num_bound_imports, num_bound_symbols
    
def get_exports(filename):
    # get number of exports and export symbols
    num_exports = 0
    num_export_symbols = 0
    try:
        pe_instance = pefile.PE(filename) 
        if hasattr(pe_instance,"DIRECTORY_ENTRY_EXPORT"):
            num_exports = len(pe_instance.DIRECTORY_ENTRY_EXPORT)
            export_symbols = list()
            for entry in pe_instance.DIRECTORY_ENTRY_EXPORT.symbols:
                if entry.name: 
                    export_symbols.append(entry.name)
                    logger.debug("Export symbols {}".format('\n'.join(export_symbols)))
            num_export_symbols = len(export_symbols)
    except Exception,e:
        logger.info("Error while getting number of export symbols in file {} - {}"
        .format.format(filename,e.message), exc_info=True) 

    return num_exports,num_export_symbols


def get_architecture(filename):
    arch = "Unknown"
    with open(filename,'rb') as f:
        f.seek(60)
        s=f.read(4)
        header_offset=struct.unpack("<L", s)[0]
        f.seek(header_offset+4)
        s=f.read(2)
        machine=struct.unpack("<H", s)[0]
        if machine == IMAGE_FILE_MACHINE_I386:
            arch = "IA-32 (32-bit x86)"
        elif machine == IMAGE_FILE_MACHINE_IA64:
            arch = "IA-64 (Itanium)"
        elif machine == IMAGE_FILE_MACHINE_AMD64:
            arch = "AMD-64 (64-bit x86)"
    return arch

def get_file_modification_time(filename):
    return datetime.datetime.fromtimestamp(os.path.getmtime(filename)).strftime("%d-%m-%Y %H:%M:%S")

def get_file_creation_time(filename):
    return datetime.datetime.fromtimestamp(os.path.getctime(filename)).strftime("%d-%m-%Y %H:%M:%S")

def get_uncommon_section_names(filename):
    std_sections = ['.code','.text', '.bss', '.rdata', '.data', '.rsrc', '.edata', '.idata', \
                   '.pdata', '.debug', '.reloc', '.stab', '.stabstr', '.tls', \
                   '.crt', '.gnu_deb', '.eh_fram', '.exptbl', '.rodata']

    uncommon_sections = list()
    try: 
        pe_instance = pefile.PE(filename)
        for sec in pe_instance.sections:
            sec.Name = RemoveNulls(sec.Name.strip().lower())
            if sec.Name not in std_sections:
                uncommon_sections.append(sec.Name)
    except Exception,e:
        logger.info("Error while getting uncommon sections in file {} - {}"
        .format.format(filename,e.message), exc_info=True) 

    return uncommon_sections

def get_major_attributes(filename):
    try: 
        pe_instance = pefile.PE(filename)
        # important attributes of PE file
        logger.info("Major version - {}".format(pe_instance.OPTIONAL_HEADER.MajorImageVersion))
        logger.info("Minor version - {}".format(pe_instance.OPTIONAL_HEADER.MinorImageVersion))
        logger.info("Major version - {}".format(pe_instance.OPTIONAL_HEADER.CheckSum))
        logger.info("Number of sections - {}".format(pe_instance.FILE_HEADER.NumberOfSections))
        logger.info("Debug size - {}".format(pe_instance.OPTIONAL_HEADER.DATA_DIRECTORY[6].Size))
        logger.info("Relative virtual address - {}".format(pe_instance.OPTIONAL_HEADER.DATA_DIRECTORY[1].VirtualAddress)) 
        logger.info("Export size - {}".format(pe_instance.OPTIONAL_HEADER.DATA_DIRECTORY[0].Size))
        logger.info("Debug size - {}".format(pe_instance.FILE_HEADER.TimeDateStamp))
        logger.info("Relative virtual addresses and sizes - {}".format(pe_instance.OPTIONAL_HEADER.NumberOfRvaAndSizes))
        logger.info("Total size - {}".format(pe_instance.__data__))
        logger.info("Virtual address - {}".format(pe_instance.sections[0].VirtualAddress))
        logger.info("Virtual size - {}".format(pe_instance.sections[0].Misc_VirtualSize))
        logger.info("Compile date - {}".format(pe_instance.FILE_HEADER.TimeDateStamp))
        logger.info("Number of relative virtual addresses and their sizes - {}".
        format(pe_instance.OPTIONAL_HEADER.NumberOfRvaAndSizes))

        logger.info("PE driver - {}".format(pe_instance.is_driver))
        logger.info("PE EXE - {}".format(pe_instance.is_exe))
        logger.info("PE DLL - {}".format(pe_instance.is_dll))
        logger.info("PE driver - {}".format(pe_instance.get_warnings))

    except Exception,e:
        logger.info("Error while getting major attributes of file {}".format(filename))

def cmd_arguments():

    try:
        parser = argparse.ArgumentParser("This script does static analysis of file and reports various file attributes."
                 " This can be used for identifying malicious files." )

        parser.add_argument('--check-file', required=True, help='full path of the file that you wish to check.', dest='check_file')
        parser.add_argument('--yara-rules-dir', required=False, help='Please specify yara rules directory', dest='yara_rules_dir')
        parser.add_argument('--compiled-yara-rules-dir', required=False, help='Please specify compiled yara rules directory',
               dest='compiled_yara_rules_dir')
        args = parser.parse_args()
        return args

    except Exception as exc:
        logger.error("Error while getting command line arguments - %s" %exc.message,exc_info=True)

if __name__ == '__main__':

    try:
        cmd_args = cmd_arguments()

        # check file exists or not
        if not os.path.isfile(cmd_args.check_file): 
            logger.info("The file {} on which you wish to do static analysis does not exist." 
                        "Quitting..".format(cmd_args.check_file)) 
            sys.exit(1)

        # check if yara directories exists or not. 
        if not os.path.isdir(cmd_args.yara_rules_dir):
            logger.info("Yara rules directory {} does not exist. Kindly ensure that yara" 
                        "is installed on the system along with the rules. Quitting now...")
            sys.exit(1)
 
        # check if yara directories exists or not. 
        if not os.path.isdir(cmd_args.compiled_yara_rules_dir):
            logger.info("Yara compiled rules directory {} does not exist. Kindly ensure that yara" 
                        "is installed on the system along with the rules. Quitting now...")
            sys.exit(1)

        #cmd_args.check_file = '/home/psj/Development/malware-static-analysis/densityscout.exe'
        
        #yara_rules ='/home/psj/Development/Yara/yara-rules'
        #compiled_yara_rules = '/home/psj/Development/Yara/compiled-yara-rules'
        
        yara_instance = yara_checks(cmd_args.yara_rules_dir,cmd_args.compiled_yara_rules_dir)

        # is another file overlayed to existing file
        overlay_flg = detect_overlay(cmd_args.check_file)
        if overlay_flg:
            logger.info("File overlay is detected")
        else:
            logger.info("File overlay is not detected")  

        # check if ip are present
        ips_present = find_ip_address(cmd_args.check_file)
        if ips_present:
            logger.info("The following IPs - {} are found in the file {}".format(ips_present,cmd_args.check_file))
        else:
            logger.info("There are no IP addresses present in the file {}".format(cmd_args.check_file))

        # check if urls are present
        urls_present = find_urls(cmd_args.check_file)
        if urls_present:
            logger.info("The following urls - {} are found in the file {}".format(urls_present,cmd_args.check_file))
        else:
            logger.info("There are no urls present in the file {}".format(cmd_args.check_file))

        # check if emails are present
        emails_present = find_emails(cmd_args.check_file)
        if emails_present:
            logger.info("The following email addresses - {} are found in the file {}"
            .format(urls_present,cmd_args.check_file))
        else:
            logger.info("There are no email addresses present in the file {}".format(cmd_args.check_file))

        # file - packer test
        logger.info("Executing packer test...")
        yara_result = yara_instance.is_packed(cmd_args.check_file)
        logger.info("Packer test results:") 
        #if yara_result:
        #    for meta_items in yara_result:  
        #        logger.info("Yara result - {}".format(meta_items))  
        #else:
        #    logger.info("No packer programs like UPX were found for the file - {}.".format(cmd_args.check_file))
        logger.info("Packer test yara results:-")
        if yara_result:
            for meta_items in yara_result:  
                logger.info("{}".format(meta_items))  
        # file  - a malicious document test 
        logger.info("Executing malicious document test...") 
        yara_result = yara_instance.is_malicious_document(cmd_args.check_file)
        logger.info("Malicious document test Yara results:")
        if yara_result:
            for meta_items in yara_result:  
                logger.info("{}".format(meta_items))  
        else:
            logger.info("No malicious document signs were detected for the file - {}.".format(cmd_args.check_file))

        # file  - anti-debug or anti-virtual machine test  
        yara_result = yara_instance.is_antiVM(cmd_args.check_file)
        if yara_result:
            for meta_items in yara_result:  
                logger.info("Yara result - {}".format(meta_items))  
        else:
            logger.info("No anti-debug or anti-VM features were detected in the file - {}.".format(cmd_args.check_file))


        # file  - crypto features test  
        yara_result = yara_instance.is_cryptofeatures(cmd_args.check_file)
        if yara_result:
            for meta_items in yara_result:  
                logger.info("Yara result - {}".format(meta_items))  
        else:
            logger.info("No functions related to cryptography/hashing etc. were found in the file - {}.".format(cmd_args.check_file))

        # file  - exploitkit test  
        yara_result = yara_instance.is_exploitkit(cmd_args.check_file)
        if yara_result:
            for meta_items in yara_result:  
                logger.info("Yara result - {}".format(meta_items))  
        else:
            logger.info("No exploitkit related signatures were triggered for the file - {}.".format(cmd_args.check_file))

        # file  - webshell test  
        yara_result = yara_instance.is_webshell(cmd_args.check_file)
        if yara_result:
            for meta_items in yara_result:  
                logger.info("Yara result - {}".format(meta_items))  
        else:
            logger.info("No webshells were detected in the file - {}.".format(cmd_args.check_file))

        # file  - CVE rules test  
        yara_result = yara_instance.is_CVErules(cmd_args.check_file)
        if yara_result:
            for meta_items in yara_result:  
                logger.info("Yara result - {}".format(meta_items))  
        else:
            logger.info("No CVE related vulnerabilities were detected in the file - {}.".format(cmd_args.check_file))

        #######################
        #  This is failing at the moment as yara is not compiled with md5 module
        #######################
        # file  - malware test  
        #yara_result = yara_instance.is_malware(cmd_args.check_file)
        #if yara_result:
        #    for meta_items in yara_result:  
        #        logger.info("Yara result - {}".format(meta_items))  
        #else:
        #    logger.info("No malware related signatures were triggered for the file - {}.".format(cmd_args.check_file))


        logger.info("Analyzing file '{}'".format(cmd_args.check_file))
 
        # file size
        result = get_file_size(cmd_args.check_file)
        logger.info("Size of file '{}' - {}".format(cmd_args.check_file, result))

        # file type
        result = mime_type(cmd_args.check_file) 
        logger.info("File type of '{}' - {}".format(cmd_args.check_file, result))

        # data entropy 
        result = compute_data_entropy(cmd_args.check_file) 
        logger.info("Data entropy of file '{}' - {}".format(cmd_args.check_file, result))

        # md5 hash
        result = compute_md5(cmd_args.check_file) 
        logger.info("MD5 hash of file '{}' - {}".format(cmd_args.check_file, result))

        # sha1 hash
        result = compute_sha1(cmd_args.check_file) 
        logger.info("SHA1 hash of file '{}' - {}".format(cmd_args.check_file, result))

        # ssdeep hash
        result = ssdeep_hash(cmd_args.check_file) 
        logger.info("ssdeep hash of file '{}' - {}".format(cmd_args.check_file, result))

        ### modify this code and print in a readable way 
        # import functions
        import_funs = get_import_dll_functions(cmd_args.check_file)
        logger.info("Import DLL functions:\n") 
        for item in import_funs: 
            logger.info("{}\n".format(item))
        logger.info("---------------------------------------") 

        logger.info("EXE status - {}".format(is_exe(cmd_args.check_file)))  
        logger.info("PE sections - {}".format(pe_sections(cmd_args.check_file)))
        logger.info("DOS headers - {}".format(dos_headers(cmd_args.check_file))) 
        logger.info("Imported DLLs - {}".format(get_import_dlls(cmd_args.check_file))) 
        logger.info("Export symbols - {}".format(get_export_symbols(cmd_args.check_file))) 

        # major attributes of file
        get_major_attributes(cmd_args.check_file)
 
        # check if it's an EXE file
        if is_exe(cmd_args.check_file):
            logger.info("{} is a EXE file.".format(cmd_args.check_file))
        else:
            logger.info("{} is not a EXE file.".format(cmd_args.check_file))

        # file creation time
        logger.info("Last accessed time - {}".format(get_file_creation_time(cmd_args.check_file)))

        # file modification time
        logger.info("Last modification time - {}".format(get_file_modification_time(cmd_args.check_file)))

        # file architecture
        logger.info("Architecure - {}".format(get_architecture(cmd_args.check_file)))

        # check if anti-debug functions are present
        antidebug_functions = get_antidebug_functions(cmd_args.check_file)
        if antidebug_functions:        
            logger.info("Anti-debug functions are found in file {} - {}".format(cmd_args.check_file, antidebug_functions))
        else:
            logger.info("No anti-debug functions are found in the file {}".format(cmd_args.check_file))

        # check if virtual machine detection functions are present
        antivm_results = antiVM_checks(cmd_args.check_file)
        if antivm_results:        
            logger.info("Anti-VM functions are found in file {} - {}".format(cmd_args.check_file, antivm_functions))
        else:
            logger.info("No anti-VM functions are found in the file {}".format(cmd_args.check_file))


        # keep track of probable suspicious api calls 
        sus_api_calls = suspicious_api_calls(cmd_args.check_file)
        if sus_api_calls:        
            logger.info("Suspicious API functions are found in file {} - {}".format(cmd_args.check_file, sus_api_calls))
        else:
            logger.info("No suspicious api calls are found in the file {}".format(cmd_args.check_file))

        # check if the file is packed using well known packer programs like UPX
        result = is_packed(cmd_args.check_file)
        if result:
            logger.info("It seems that the file is packed using packer programs.")
        else:
            logger.info("No usage of packer program is detected")

        # raw data value check in file sections
        result = check_sizeofrawdata(cmd_args.check_file)
        if not result:
            logger.info("The Size Of Raw data value is not valid and it may crash your disassembler/debugger")
        else:
            logger.info("The size of Raw data value in file sections is OK.")

        # check if section name is empty 
        result = check_empty_section_name(cmd_args.check_file)
        if result:
            logger.info("One of the section name(s) in file are empty or non-ASCII") 
        else:
            logger.info("Non-ASCII or empty section names are not present") 

        # check optional header size - illegal or not
        result = check_optional_header_size(cmd_args.check_file)
        if result:
            logger.info("Size of Optional header in file {} is OK.".format(cmd_args.check_file))
        else:
              logger.info("Size of Optional header in file {} is not OK.".format(cmd_args.check_file))

        # optional header checksum 
        result = check_optional_header_checksum(cmd_args.check_file)  
        if result:
            logger.info("Checksum of optional header in file {} is valid".format(cmd_args.check_file))
        else:
            logger.info("Checksum of optional header in file {} is not valid".format(cmd_args.check_file))

        # check if the file contains service DLLs  
        result = check_service_dll(cmd_args.check_file)
        if result:
            logger.info("The file contains service DLLs.Looks like a Windows service")
        else:
            logger.info("Service DLLs are not present in file."
             "Probably, not a Windows service")  

        # Number of imports and number of import symbols
        n_import,n_import_symbols = get_imports(cmd_args.check_file)
        logger.info("Number of imports and Number of import symbols are - {}, {}"
        .format(n_import,n_import_symbols))

        # Number of imports and number of import symbols
        n_export,n_export_symbols = get_exports(cmd_args.check_file)
        logger.info("Number of exports and Number of export symbols are - {}, {}"
        .format(n_export,n_export_symbols))

        # Number of bound imports and number of bound import symbols        
        n_bound_import,n_bound_import_symbols = get_bound_imports(cmd_args.check_file)        
        logger.info("Number of bound imports and Number of bound import symbols"
        " are - {}, {}".format(n_bound_import, n_bound_import_symbols))

        # uncommon sections
        uncommon_sections = get_uncommon_section_names(cmd_args.check_file)
        if uncommon_sections:
            logger.info("Uncommon sections in file {} are {}"
            .format(cmd_args.check_file,'\n'.join(uncommon_sections)))
        else:
            logger.info("No uncommon sections found in file {}".format(cmd_args.check_file))

        # check if PE file supports kernel mode of operation
        kernel_check = check_kernel_mode(cmd_args.check_file)
        if kernel_check:
            logger.info("The file {} supports kernel mode of operations".format(cmd_args.check_file))
        else:
            logger.info("The file {} does not support kernel mode of operations".format(cmd_args.check_file))

        # check if the file acts as windows service
        service_check = check_dynamic_loaders(cmd_args.check_file)
        if service_check:
            logger.info("The file {} does contain functionality to act as Windows service".format(cmd_args.check_file))
        else:
            logger.info("The file {} does not contain functionality to act as Windows service".format(cmd_args.check_file))

        sys.exit(1)

    except Exception,e:
        logger.error("Error while running malware static analyzer script -  {}".format(e.message),exc_info=True)
    
